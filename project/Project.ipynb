{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проект \"Анализ веб-документов\" Техносфера Весна 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:17.555676Z",
     "iopub.status.busy": "2021-05-31T12:41:17.555313Z",
     "iopub.status.idle": "2021-05-31T12:41:18.508378Z",
     "shell.execute_reply": "2021-05-31T12:41:18.507587Z",
     "shell.execute_reply.started": "2021-05-31T12:41:17.555600Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ноутбук работал на каггле, так как там для соревнования бесплатно дается 16 гб оперативной памяти и 4 ядра для вычислений. Также там есть поддержка GPU ускорения, которое могло бы понадобиться для XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:18.511676Z",
     "iopub.status.busy": "2021-05-31T12:41:18.511434Z",
     "iopub.status.idle": "2021-05-31T12:41:18.517334Z",
     "shell.execute_reply": "2021-05-31T12:41:18.516533Z",
     "shell.execute_reply.started": "2021-05-31T12:41:18.511652Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_data = \"../input/anomaly-detection-competition-ml1-ts-spring-2021/\"\n",
    "path_to_content = \"../input/spheredata/content/content/\"\n",
    "path_to_parsed = \"../input/spheredata/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на наши трейновые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:18.521084Z",
     "iopub.status.busy": "2021-05-31T12:41:18.520785Z",
     "iopub.status.idle": "2021-05-31T12:41:18.571999Z",
     "shell.execute_reply": "2021-05-31T12:41:18.571284Z",
     "shell.execute_reply.started": "2021-05-31T12:41:18.521061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11690, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>15764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>14852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         group_id  doc_id  target\n",
       "pair_id                          \n",
       "1               1   15731       0\n",
       "2               1   14829       0\n",
       "3               1   15764       0\n",
       "4               1   17669       0\n",
       "5               1   14852       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf = pd.read_csv(path_to_data + 'train_groups.csv', sep=',', index_col='pair_id')\n",
    "print(traindf.shape)\n",
    "traindf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Идея 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на каждые заголовки, построим множество признаков, основанных на количестве схожих слов в заголовках.\n",
    "Будем брать топ 15 в списке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение 0\n",
    "Повторим решение со второй домашней работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Прочитаем все заголовки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:18.575068Z",
     "iopub.status.busy": "2021-05-31T12:41:18.574808Z",
     "iopub.status.idle": "2021-05-31T12:41:18.739649Z",
     "shell.execute_reply": "2021-05-31T12:41:18.738796Z",
     "shell.execute_reply.started": "2021-05-31T12:41:18.575045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>М. Б. Аншина Центр репродукции и генетики «Фер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Переводы Киви кошелька</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ПРОЕКТ ПАТРУЛИ ВРЕМЕНИ - РЕАБИЛИТАЦИЯ ДУХОВНЫХ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Блог - Клуб  \" Преподавание в начальных класса...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title\n",
       "doc_id                                                   \n",
       "1       М. Б. Аншина Центр репродукции и генетики «Фер...\n",
       "2                                  Переводы Киви кошелька\n",
       "3       ПРОЕКТ ПАТРУЛИ ВРЕМЕНИ - РЕАБИЛИТАЦИЯ ДУХОВНЫХ...\n",
       "4       Блог - Клуб  \" Преподавание в начальных класса..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_to_title = {}\n",
    "\n",
    "with open(path_to_data + 'docs_titles.tsv') as f:\n",
    "    for num_line, line in enumerate(f):\n",
    "        if num_line == 0:\n",
    "            continue\n",
    "        data = line.strip().split('\\t', 1)\n",
    "        doc_to_title[int(data[0])] = '' if len(data) == 1 else data[1]\n",
    "\n",
    "filesdf = pd.DataFrame.from_dict(doc_to_title, orient='index', columns=['title'])\n",
    "filesdf.index.name = 'doc_id'\n",
    "filesdf.sort_index(inplace=True)\n",
    "filesdf.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Прочитаем трейн и добавим заголовки к нему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:18.742621Z",
     "iopub.status.busy": "2021-05-31T12:41:18.742379Z",
     "iopub.status.idle": "2021-05-31T12:41:18.760556Z",
     "shell.execute_reply": "2021-05-31T12:41:18.759705Z",
     "shell.execute_reply.started": "2021-05-31T12:41:18.742597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>15764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         group_id  doc_id  target\n",
       "pair_id                          \n",
       "1               1   15731       0\n",
       "2               1   14829       0\n",
       "3               1   15764       0\n",
       "4               1   17669       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf = pd.read_csv(path_to_data + 'train_groups.csv', index_col='pair_id')\n",
    "traindf.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Найдем признаки. Посчитаем общие слова для всех групп и всех веб-страниц в заголовке. Как признаки для веб-страницы, возьмем значения топ-15  пересечений с другими страницами из группы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:18.762037Z",
     "iopub.status.busy": "2021-05-31T12:41:18.761691Z",
     "iopub.status.idle": "2021-05-31T12:41:18.768451Z",
     "shell.execute_reply": "2021-05-31T12:41:18.767458Z",
     "shell.execute_reply.started": "2021-05-31T12:41:18.762003Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(group_df):\n",
    "    titles = filesdf.loc[group_df['doc_id'].values].title\n",
    "    matrix = []\n",
    "    for i, title in enumerate(titles):\n",
    "        words = set(title.strip().split())\n",
    "        distances = []\n",
    "        for j, another_title in enumerate(titles):\n",
    "            if i == j:\n",
    "                continue\n",
    "            another_words = set(another_title.strip().split())\n",
    "            distances.append(len(words.intersection(another_words)))\n",
    "        fueatures_to_add = (-np.partition(-np.asarray(distances, dtype='int'), 15)[:15])\n",
    "        matrix.append(-np.sort(-fueatures_to_add))\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:18.770581Z",
     "iopub.status.busy": "2021-05-31T12:41:18.769936Z",
     "iopub.status.idle": "2021-05-31T12:41:18.777870Z",
     "shell.execute_reply": "2021-05-31T12:41:18.776957Z",
     "shell.execute_reply.started": "2021-05-31T12:41:18.770539Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features_for_dataframe(df):\n",
    "    X = None\n",
    "    for group_id in df.group_id.unique():\n",
    "        X = sparse.vstack((X, extract_features(df[df.group_id == group_id])))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:18.781529Z",
     "iopub.status.busy": "2021-05-31T12:41:18.781193Z",
     "iopub.status.idle": "2021-05-31T12:41:18.788154Z",
     "shell.execute_reply": "2021-05-31T12:41:18.787303Z",
     "shell.execute_reply.started": "2021-05-31T12:41:18.781497Z"
    }
   },
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'max_iter': [1000, 2000, 3000, 5000],\n",
    "    'loss': ['hinge', 'log', 'squared_hinge'],\n",
    "    'alpha': np.logspace(3, -3, 10),\n",
    "    'penalty': ['l1', 'l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:18.790878Z",
     "iopub.status.busy": "2021-05-31T12:41:18.790613Z",
     "iopub.status.idle": "2021-05-31T12:41:18.800692Z",
     "shell.execute_reply": "2021-05-31T12:41:18.799657Z",
     "shell.execute_reply.started": "2021-05-31T12:41:18.790855Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = extract_features_for_dataframe(traindf)\n",
    "y_train = np.asarray(traindf['target'])\n",
    "groups = np.asarray(traindf['group_id'])\n",
    "\n",
    "scaler = StandardScaler(with_mean=False).fit(X_train, y_train)\n",
    "X_train = scaler.transform(X_train);\n",
    "\n",
    "searcher = GridSearchCV(SGDClassifier(), grid, scoring='f1', n_jobs=-1, pre_dispatch='2*n_jobs')\n",
    "searcher.fit(X_train, y_train, groups=groups);\n",
    "\n",
    "best_params = { 'n_jobs': -1 }\n",
    "best_params.update(searcher.best_params_)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверим наше предсказание на датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:18.803636Z",
     "iopub.status.busy": "2021-05-31T12:41:18.803384Z",
     "iopub.status.idle": "2021-05-31T12:41:18.809446Z",
     "shell.execute_reply": "2021-05-31T12:41:18.808684Z",
     "shell.execute_reply.started": "2021-05-31T12:41:18.803614Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_val, X_val, y_train_val, y_val = train_test_split(X_train, y_train, random_state=42)\n",
    "\n",
    "clf = SGDClassifier(**best_params).fit(X_train_val, y_train_val)\n",
    "y_pred = clf.predict(X_val)\n",
    "f1_score(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Считываем test и делаем predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:18.812444Z",
     "iopub.status.busy": "2021-05-31T12:41:18.812195Z",
     "iopub.status.idle": "2021-05-31T12:41:18.838796Z",
     "shell.execute_reply": "2021-05-31T12:41:18.837966Z",
     "shell.execute_reply.started": "2021-05-31T12:41:18.812423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11691</th>\n",
       "      <td>130</td>\n",
       "      <td>6710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11692</th>\n",
       "      <td>130</td>\n",
       "      <td>4030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11693</th>\n",
       "      <td>130</td>\n",
       "      <td>5561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11694</th>\n",
       "      <td>130</td>\n",
       "      <td>4055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         group_id  doc_id\n",
       "pair_id                  \n",
       "11691         130    6710\n",
       "11692         130    4030\n",
       "11693         130    5561\n",
       "11694         130    4055"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf = pd.read_csv(path_to_data + 'test_groups.csv', index_col='pair_id')\n",
    "testdf.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:18.840451Z",
     "iopub.status.busy": "2021-05-31T12:41:18.840081Z",
     "iopub.status.idle": "2021-05-31T12:41:18.844302Z",
     "shell.execute_reply": "2021-05-31T12:41:18.843178Z",
     "shell.execute_reply.started": "2021-05-31T12:41:18.840414Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = extract_features_for_dataframe(testdf)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = SGDClassifier(**best_params).fit(X_train, y_train)\n",
    "testdf['target'] = clf.predict(X_test)\n",
    "\n",
    "testdf.drop(columns=['group_id', 'doc_id']).to_csv('solution0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итоговый скор 0.51914\n",
    "Надо что-то получше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Идея 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на слова в получившихся данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:18.846190Z",
     "iopub.status.busy": "2021-05-31T12:41:18.845794Z",
     "iopub.status.idle": "2021-05-31T12:41:18.853101Z",
     "shell.execute_reply": "2021-05-31T12:41:18.852254Z",
     "shell.execute_reply.started": "2021-05-31T12:41:18.846155Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:18.854703Z",
     "iopub.status.busy": "2021-05-31T12:41:18.854282Z",
     "iopub.status.idle": "2021-05-31T12:41:18.997840Z",
     "shell.execute_reply": "2021-05-31T12:41:18.997095Z",
     "shell.execute_reply.started": "2021-05-31T12:41:18.854670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('-', 11915), ('в', 6517), ('и', 5654), ('|', 4754), ('на', 4269)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCounter = Counter()\n",
    "for title in filesdf['title'].values:\n",
    "    wordCounter.update(title.strip().split())\n",
    "wordCounter.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Явно среди заголовков оказалось куча мусора и бесполезной информации.\n",
    "Давайте предобработаем заголовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:19.000367Z",
     "iopub.status.busy": "2021-05-31T12:41:18.999796Z",
     "iopub.status.idle": "2021-05-31T12:41:29.933032Z",
     "shell.execute_reply": "2021-05-31T12:41:29.932092Z",
     "shell.execute_reply.started": "2021-05-31T12:41:19.000325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 717 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docopt>=0.6\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Collecting dawg-python>=0.7.1\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.2 MB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=f120eb93e6c69d69e68bacc2311940cdffc18ce2ed3321d9dacf26617c354eb3\n",
      "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
      "Successfully built docopt\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:29.934887Z",
     "iopub.status.busy": "2021-05-31T12:41:29.934571Z",
     "iopub.status.idle": "2021-05-31T12:41:30.373926Z",
     "shell.execute_reply": "2021-05-31T12:41:30.373097Z",
     "shell.execute_reply.started": "2021-05-31T12:41:29.934843Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import corpus, word_tokenize\n",
    "from string import digits, punctuation\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:30.375488Z",
     "iopub.status.busy": "2021-05-31T12:41:30.375154Z",
     "iopub.status.idle": "2021-05-31T12:41:30.713389Z",
     "shell.execute_reply": "2021-05-31T12:41:30.712540Z",
     "shell.execute_reply.started": "2021-05-31T12:41:30.375454Z"
    }
   },
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(u\"[^\\U00000000-\\U0000d7ff\\U0000e000-\\U0000ffff]\", flags=re.UNICODE)\n",
    "\n",
    "chars_to_remove = digits + punctuation + \"–—«»№•❤★✿╬·…®°º™►\"\n",
    "morph = MorphAnalyzer()\n",
    "RU_stopwords = set(corpus.stopwords.words('russian'))\n",
    "EN_stopwords = set(corpus.stopwords.words('english'))\n",
    "GE_stopwords = set(corpus.stopwords.words('german'))\n",
    "stopwords = RU_stopwords.union(EN_stopwords.union(GE_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:30.715196Z",
     "iopub.status.busy": "2021-05-31T12:41:30.714831Z",
     "iopub.status.idle": "2021-05-31T12:41:30.720981Z",
     "shell.execute_reply": "2021-05-31T12:41:30.719880Z",
     "shell.execute_reply.started": "2021-05-31T12:41:30.715161Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    if text is None:\n",
    "        return\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    text = text.translate(str.maketrans('', '', chars_to_remove))\n",
    "    words = word_tokenize(text)\n",
    "    return [morph.parse(word)[0].normal_form for word in words \n",
    "             if word not in stopwords and len(word) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:41:30.722685Z",
     "iopub.status.busy": "2021-05-31T12:41:30.722340Z",
     "iopub.status.idle": "2021-05-31T12:42:18.089789Z",
     "shell.execute_reply": "2021-05-31T12:42:18.088857Z",
     "shell.execute_reply.started": "2021-05-31T12:41:30.722648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[аншина, центр, репродукция, генетика, фертиме...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[перевод, киви, кошелёк]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[проект, патруль, время, реабилитация, духовны...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[блог, клуб, преподавание, начальный, класс, п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[как, быстро, понизить, холестерин, высокий, х...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title_words\n",
       "doc_id                                                   \n",
       "1       [аншина, центр, репродукция, генетика, фертиме...\n",
       "2                                [перевод, киви, кошелёк]\n",
       "3       [проект, патруль, время, реабилитация, духовны...\n",
       "4       [блог, клуб, преподавание, начальный, класс, п...\n",
       "5       [как, быстро, понизить, холестерин, высокий, х..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesdf['title_words'] = filesdf['title'].apply(process_text)\n",
    "filesdf.drop(columns=['title'], inplace=True)\n",
    "filesdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим как изменились наши заголовки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:18.091377Z",
     "iopub.status.busy": "2021-05-31T12:42:18.091054Z",
     "iopub.status.idle": "2021-05-31T12:42:18.184105Z",
     "shell.execute_reply": "2021-05-31T12:42:18.183140Z",
     "shell.execute_reply.started": "2021-05-31T12:42:18.091341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('как', 4036),\n",
       " ('форум', 1714),\n",
       " ('скачать', 1246),\n",
       " ('страница', 1040),\n",
       " ('онлайн', 949),\n",
       " ('бесплатно', 822),\n",
       " ('российский', 803),\n",
       " ('что', 802),\n",
       " ('новость', 738),\n",
       " ('гта', 659)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_wordCounter = Counter()\n",
    "for words in filesdf['title_words'].values:\n",
    "    new_wordCounter.update(words)\n",
    "new_wordCounter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уже лучше, попробуем запустить решение 0 на этих данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:18.185846Z",
     "iopub.status.busy": "2021-05-31T12:42:18.185504Z",
     "iopub.status.idle": "2021-05-31T12:42:18.192282Z",
     "shell.execute_reply": "2021-05-31T12:42:18.191366Z",
     "shell.execute_reply.started": "2021-05-31T12:42:18.185811Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(group_df):\n",
    "    words = filesdf.loc[group_df['doc_id'].values].title_words\n",
    "    matrix = []\n",
    "    for i, current_words in enumerate(words):\n",
    "        distances = []\n",
    "        for j, another_words in enumerate(words):\n",
    "            if i == j:\n",
    "                continue\n",
    "            distances.append(len(set(current_words) & set(another_words)))\n",
    "        fueatures_to_add = (-np.partition(-np.asarray(distances, dtype='int'), 15)[:15])\n",
    "        matrix.append(-np.sort(-fueatures_to_add))\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:18.194009Z",
     "iopub.status.busy": "2021-05-31T12:42:18.193478Z",
     "iopub.status.idle": "2021-05-31T12:42:18.202403Z",
     "shell.execute_reply": "2021-05-31T12:42:18.201608Z",
     "shell.execute_reply.started": "2021-05-31T12:42:18.193974Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = extract_features_for_dataframe(traindf)\n",
    "y_train = np.asarray(traindf['target'])\n",
    "groups = np.asarray(traindf['group_id'])\n",
    "\n",
    "scaler = StandardScaler(with_mean=False).fit(X_train, y_train)\n",
    "X_train = scaler.transform(X_train);\n",
    "\n",
    "searcher = GridSearchCV(SGDClassifier(), grid, scoring='f1', n_jobs=-1, pre_dispatch='2*n_jobs')\n",
    "searcher.fit(X_train, y_train, groups=groups);\n",
    "\n",
    "best_params = { 'n_jobs': -1 }\n",
    "best_params.update(searcher.best_params_)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверим наше предсказание на датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:18.208449Z",
     "iopub.status.busy": "2021-05-31T12:42:18.208106Z",
     "iopub.status.idle": "2021-05-31T12:42:18.213536Z",
     "shell.execute_reply": "2021-05-31T12:42:18.212721Z",
     "shell.execute_reply.started": "2021-05-31T12:42:18.208404Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_val, X_val, y_train_val, y_val = train_test_split(X_train, y_train, random_state=42)\n",
    "\n",
    "clf = SGDClassifier(**best_params).fit(X_train_val, y_train_val)\n",
    "y_pred = clf.predict(X_val)\n",
    "f1_score(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Считываем test и делаем predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:18.216692Z",
     "iopub.status.busy": "2021-05-31T12:42:18.216057Z",
     "iopub.status.idle": "2021-05-31T12:42:18.223213Z",
     "shell.execute_reply": "2021-05-31T12:42:18.222363Z",
     "shell.execute_reply.started": "2021-05-31T12:42:18.216655Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = extract_features_for_dataframe(testdf)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = SGDClassifier(**best_params).fit(X_train, y_train)\n",
    "testdf['target'] = clf.predict(X_test)\n",
    "\n",
    "testdf.drop(columns=['group_id', 'doc_id']).to_csv('solution1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итоговый скор 0.65689\n",
    "Ура, побили бейзлайн! Явно самих заголовков не хватает. Давайте обкачаем наши данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:18.225051Z",
     "iopub.status.busy": "2021-05-31T12:42:18.224331Z",
     "iopub.status.idle": "2021-05-31T12:42:25.785727Z",
     "shell.execute_reply": "2021-05-31T12:42:25.784829Z",
     "shell.execute_reply.started": "2021-05-31T12:42:18.225014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.2.1-py3-none-any.whl (33 kB)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1273 sha256=dfd5b589f297b24bfc9acb6a9481df5df5c4b6395bd339d7b3d1410febd886da\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/9e/ba/20e5bbc1afef3a491f0b3bb74d508f99403aabe76eda2167ca\n",
      "Successfully built bs4\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.9.3 bs4-0.0.1 soupsieve-2.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:25.789341Z",
     "iopub.status.busy": "2021-05-31T12:42:25.789080Z",
     "iopub.status.idle": "2021-05-31T12:42:25.930453Z",
     "shell.execute_reply": "2021-05-31T12:42:25.929691Z",
     "shell.execute_reply.started": "2021-05-31T12:42:25.789310Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим имя URL без домена и путь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:25.932153Z",
     "iopub.status.busy": "2021-05-31T12:42:25.931666Z",
     "iopub.status.idle": "2021-05-31T12:42:25.937107Z",
     "shell.execute_reply": "2021-05-31T12:42:25.936113Z",
     "shell.execute_reply.started": "2021-05-31T12:42:25.932116Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_url(url):\n",
    "    first_slash = url.find('/')\n",
    "    last_dot = (url if first_slash == -1 else url[:first_slash]).rfind('.')\n",
    "    return {\n",
    "        \"url_name\": url[:last_dot]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из головы достанем верификацию от гугла, а также информацию о ключевых словах и описании"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:25.938886Z",
     "iopub.status.busy": "2021-05-31T12:42:25.938390Z",
     "iopub.status.idle": "2021-05-31T12:42:25.948747Z",
     "shell.execute_reply": "2021-05-31T12:42:25.947828Z",
     "shell.execute_reply.started": "2021-05-31T12:42:25.938848Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_head(head):\n",
    "    if head is None:\n",
    "        return {\n",
    "            'verified': 0,\n",
    "            'auxiliary': []\n",
    "        }\n",
    "    verified = int(head.find('meta', attrs={'name': \"google-site-verification\"}) is not None)\n",
    "\n",
    "    keywords = head.find('meta', attrs={'name': \"keywords\", 'content': True})\n",
    "    keywords = [] if keywords is None else process_text(keywords['content'])\n",
    "\n",
    "    description = head.find('meta', attrs={'name': \"description\", \"content\": True})\n",
    "    description = [] if description is None else process_text(description['content'])\n",
    "\n",
    "    return {\n",
    "        'verified': verified,\n",
    "        'auxiliary': keywords + description\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из тела возьмем весь читабельный текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:25.950537Z",
     "iopub.status.busy": "2021-05-31T12:42:25.950015Z",
     "iopub.status.idle": "2021-05-31T12:42:25.957814Z",
     "shell.execute_reply": "2021-05-31T12:42:25.957049Z",
     "shell.execute_reply.started": "2021-05-31T12:42:25.950501Z"
    }
   },
   "outputs": [],
   "source": [
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def get_visible_text(body):\n",
    "    texts = body.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)\n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "def process_body(body):\n",
    "    return {\n",
    "        \"text\": process_text(get_visible_text(body)) if body is not None else []\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция обработки страницы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:25.959653Z",
     "iopub.status.busy": "2021-05-31T12:42:25.959092Z",
     "iopub.status.idle": "2021-05-31T12:42:25.967292Z",
     "shell.execute_reply": "2021-05-31T12:42:25.966562Z",
     "shell.execute_reply.started": "2021-05-31T12:42:25.959617Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_page(file):\n",
    "    url = file.readline().strip()\n",
    "    soup = BeautifulSoup(file, 'html.parser')\n",
    "    page_info = dict()\n",
    "    page_info.update(process_url(url))\n",
    "    page_info.update(process_head(soup.find('head')))\n",
    "    page_info.update(process_body(soup.find('body')))\n",
    "    return page_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на какой-нибудь файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:25.969102Z",
     "iopub.status.busy": "2021-05-31T12:42:25.968575Z",
     "iopub.status.idle": "2021-05-31T12:42:25.976473Z",
     "shell.execute_reply": "2021-05-31T12:42:25.975683Z",
     "shell.execute_reply.started": "2021-05-31T12:42:25.969067Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_doc(doc_id):\n",
    "    with codecs.open(path_to_content + f'{doc_id}.dat', 'r', 'utf-8') as f:\n",
    "        return process_page(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:25.978102Z",
     "iopub.status.busy": "2021-05-31T12:42:25.977744Z",
     "iopub.status.idle": "2021-05-31T12:42:25.989067Z",
     "shell.execute_reply": "2021-05-31T12:42:25.988276Z",
     "shell.execute_reply.started": "2021-05-31T12:42:25.978071Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_docs(doc_ids):\n",
    "    return {doc_id: process_doc(doc_id) for doc_id in doc_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:25.990847Z",
     "iopub.status.busy": "2021-05-31T12:42:25.990229Z",
     "iopub.status.idle": "2021-05-31T12:42:26.858021Z",
     "shell.execute_reply": "2021-05-31T12:42:26.857234Z",
     "shell.execute_reply.started": "2021-05-31T12:42:25.990813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('железа', 59),\n",
       " ('щитовидный', 56),\n",
       " ('гормон', 35),\n",
       " ('определение', 34),\n",
       " ('анализ', 33),\n",
       " ('кровь', 33),\n",
       " ('ошибка', 32),\n",
       " ('лабораторный', 31),\n",
       " ('гормональный', 30),\n",
       " ('уровень', 30)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(process_doc(1)['text']).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы обкачать все файлы явно одной моей машины не хватит, будем абузить кагл!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обкачивание данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:26.859655Z",
     "iopub.status.busy": "2021-05-31T12:42:26.859306Z",
     "iopub.status.idle": "2021-05-31T12:42:26.870143Z",
     "shell.execute_reply": "2021-05-31T12:42:26.869222Z",
     "shell.execute_reply.started": "2021-05-31T12:42:26.859621Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from tqdm.contrib.concurrent import process_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:26.873367Z",
     "iopub.status.busy": "2021-05-31T12:42:26.872707Z",
     "iopub.status.idle": "2021-05-31T12:42:26.877922Z",
     "shell.execute_reply": "2021-05-31T12:42:26.877152Z",
     "shell.execute_reply.started": "2021-05-31T12:42:26.873331Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_to_array(arr, func, **kwargs):\n",
    "    func_wrapper = partial(func, **kwargs)\n",
    "    return process_map(func_wrapper, arr, chunksize=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я разбил дальнейшее обкачивание на 6 кагл ноутбуков, чтобы быстрее все обкачивать и чтобы все влезало в оперативную память, на этот ноутбук выпала третья часть всех данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:26.879521Z",
     "iopub.status.busy": "2021-05-31T12:42:26.879074Z",
     "iopub.status.idle": "2021-05-31T12:42:26.890765Z",
     "shell.execute_reply": "2021-05-31T12:42:26.889765Z",
     "shell.execute_reply.started": "2021-05-31T12:42:26.879487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23356, 28026)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = np.array_split(filesdf.index, 6)\n",
    "current_chunks = chunks[5]\n",
    "current_chunks[0], current_chunks[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:26.892667Z",
     "iopub.status.busy": "2021-05-31T12:42:26.892277Z",
     "iopub.status.idle": "2021-05-31T12:42:26.898687Z",
     "shell.execute_reply": "2021-05-31T12:42:26.897970Z",
     "shell.execute_reply.started": "2021-05-31T12:42:26.892590Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# all_data = dict()\n",
    "# for doc_id, data in enumerate(apply_to_array(current_chunks, extract_data), start=1):\n",
    "#     all_data.update({doc_id : data})\n",
    "# len(all_data)\n",
    "\n",
    "# pd.DataFrame.from_dict(all_data, orient='index').to_csv('data'+str(current_chunks[0])+'to'+str(current_chunks[-1])+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:50:52.009873Z",
     "iopub.status.busy": "2021-05-30T14:50:52.009407Z",
     "iopub.status.idle": "2021-05-30T14:50:52.016467Z",
     "shell.execute_reply": "2021-05-30T14:50:52.015367Z",
     "shell.execute_reply.started": "2021-05-30T14:50:52.009832Z"
    }
   },
   "source": [
    "Соберем теперь все обкаченные данные в один датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:42:26.900431Z",
     "iopub.status.busy": "2021-05-31T12:42:26.900060Z",
     "iopub.status.idle": "2021-05-31T12:45:57.236781Z",
     "shell.execute_reply": "2021-05-31T12:45:57.235966Z",
     "shell.execute_reply.started": "2021-05-31T12:42:26.900396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6b38c680424c59bc6fbdb70b59c07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_words</th>\n",
       "      <th>url_name</th>\n",
       "      <th>verified</th>\n",
       "      <th>auxiliary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[аншина, центр, репродукция, генетика, фертиме...</td>\n",
       "      <td>zrenielib</td>\n",
       "      <td>1.0</td>\n",
       "      <td>аншина центр репродукция генетика фертимед мос...</td>\n",
       "      <td>аншина центр репродукция генетика фертимед мос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[перевод, киви, кошелёк]</td>\n",
       "      <td>kak-perevesti-online</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>главный перевод киви кошелёк перевод киви коше...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[проект, патруль, время, реабилитация, духовны...</td>\n",
       "      <td>timecops</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>проект патруль время реабилитация духовный сущ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[блог, клуб, преподавание, начальный, класс, п...</td>\n",
       "      <td>proffi95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>блог клуб преподавание начальный класс</td>\n",
       "      <td>размер шрифт цвет сайт изображение выклый шриф...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title_words  \\\n",
       "doc_id                                                      \n",
       "1       [аншина, центр, репродукция, генетика, фертиме...   \n",
       "2                                [перевод, киви, кошелёк]   \n",
       "3       [проект, патруль, время, реабилитация, духовны...   \n",
       "4       [блог, клуб, преподавание, начальный, класс, п...   \n",
       "\n",
       "                    url_name  verified  \\\n",
       "doc_id                                   \n",
       "1                  zrenielib       1.0   \n",
       "2       kak-perevesti-online       0.0   \n",
       "3                   timecops       0.0   \n",
       "4                   proffi95       0.0   \n",
       "\n",
       "                                                auxiliary  \\\n",
       "doc_id                                                      \n",
       "1       аншина центр репродукция генетика фертимед мос...   \n",
       "2                                                           \n",
       "3                                                           \n",
       "4                  блог клуб преподавание начальный класс   \n",
       "\n",
       "                                                     text  \n",
       "doc_id                                                     \n",
       "1       аншина центр репродукция генетика фертимед мос...  \n",
       "2       главный перевод киви кошелёк перевод киви коше...  \n",
       "3       проект патруль время реабилитация духовный сущ...  \n",
       "4       размер шрифт цвет сайт изображение выклый шриф...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_df(chunk):\n",
    "    cur_df = pd.read_csv(path_to_parsed + 'data'+str(chunk[0]) + 'to' + str(chunk[-1]) + '.csv', index_col=0)\n",
    "    cur_df.index = range(chunk[0], chunk[-1] + 1)\n",
    "    trans = lambda s: s.translate(str.maketrans('', '', \"'[,]\"))\n",
    "    cur_df['auxiliary'] = cur_df['auxiliary'].apply(trans)\n",
    "    cur_df['text'] = cur_df['text'].apply(trans)\n",
    "    return cur_df\n",
    "\n",
    "for i, df in enumerate(apply_to_array(chunks, get_df)):\n",
    "    current_chunk = chunks[i]\n",
    "    filesdf.loc[current_chunk[0]:current_chunk[-1], df.columns] = df\n",
    "\n",
    "filesdf.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:45:57.238518Z",
     "iopub.status.busy": "2021-05-31T12:45:57.238183Z",
     "iopub.status.idle": "2021-05-31T12:45:57.279059Z",
     "shell.execute_reply": "2021-05-31T12:45:57.278028Z",
     "shell.execute_reply.started": "2021-05-31T12:45:57.238484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_words</th>\n",
       "      <th>url_name</th>\n",
       "      <th>verified</th>\n",
       "      <th>auxiliary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>аншина центр репродукция генетика фертимед москва</td>\n",
       "      <td>zrenielib</td>\n",
       "      <td>1.0</td>\n",
       "      <td>аншина центр репродукция генетика фертимед мос...</td>\n",
       "      <td>аншина центр репродукция генетика фертимед мос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>перевод киви кошелёк</td>\n",
       "      <td>kak-perevesti-online</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>главный перевод киви кошелёк перевод киви коше...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>проект патруль время реабилитация духовный сущ...</td>\n",
       "      <td>timecops</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>проект патруль время реабилитация духовный сущ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>блог клуб преподавание начальный класс портал ...</td>\n",
       "      <td>proffi95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>блог клуб преподавание начальный класс</td>\n",
       "      <td>размер шрифт цвет сайт изображение выклый шриф...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title_words  \\\n",
       "doc_id                                                      \n",
       "1       аншина центр репродукция генетика фертимед москва   \n",
       "2                                    перевод киви кошелёк   \n",
       "3       проект патруль время реабилитация духовный сущ...   \n",
       "4       блог клуб преподавание начальный класс портал ...   \n",
       "\n",
       "                    url_name  verified  \\\n",
       "doc_id                                   \n",
       "1                  zrenielib       1.0   \n",
       "2       kak-perevesti-online       0.0   \n",
       "3                   timecops       0.0   \n",
       "4                   proffi95       0.0   \n",
       "\n",
       "                                                auxiliary  \\\n",
       "doc_id                                                      \n",
       "1       аншина центр репродукция генетика фертимед мос...   \n",
       "2                                                           \n",
       "3                                                           \n",
       "4                  блог клуб преподавание начальный класс   \n",
       "\n",
       "                                                     text  \n",
       "doc_id                                                     \n",
       "1       аншина центр репродукция генетика фертимед мос...  \n",
       "2       главный перевод киви кошелёк перевод киви коше...  \n",
       "3       проект патруль время реабилитация духовный сущ...  \n",
       "4       размер шрифт цвет сайт изображение выклый шриф...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesdf['title_words'] = filesdf['title_words'].apply(lambda l: \" \".join(l))\n",
    "filesdf.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Держать слова в листах оказалось не очень хорошей идеей, надо было после исправления сделать джоин, чтобы сохранять строку, так как в итоге все равно все векторайзеры работают с большой строкой :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Идея 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте добавим в качестве признаков не только расстояния между тайтлами, но и косинусовые расстояния между текстами, а также их средние, медианы и все остальное. Для этого для начала добавим в датафрейм данных 60 наиболее встречающихся слов среди всего текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:45:57.280807Z",
     "iopub.status.busy": "2021-05-31T12:45:57.280465Z",
     "iopub.status.idle": "2021-05-31T12:45:57.285350Z",
     "shell.execute_reply": "2021-05-31T12:45:57.284053Z",
     "shell.execute_reply.started": "2021-05-31T12:45:57.280771Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from collections import Counter\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:45:57.287706Z",
     "iopub.status.busy": "2021-05-31T12:45:57.287051Z",
     "iopub.status.idle": "2021-05-31T12:45:57.294999Z",
     "shell.execute_reply": "2021-05-31T12:45:57.294178Z",
     "shell.execute_reply.started": "2021-05-31T12:45:57.287666Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_to_subdf(df, attr, func, **kwargs):\n",
    "    values = getattr(df, attr).unique()\n",
    "    splitted_dfs = [df[getattr(df, attr) == val] for val in values]\n",
    "    return apply_to_array(splitted_dfs, func, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:45:57.297002Z",
     "iopub.status.busy": "2021-05-31T12:45:57.296540Z",
     "iopub.status.idle": "2021-05-31T12:48:03.037013Z",
     "shell.execute_reply": "2021-05-31T12:48:03.036086Z",
     "shell.execute_reply.started": "2021-05-31T12:45:57.296879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bd7c814b814340b32fd8f86be00aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28026 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_max_features(doc_df, max_features):\n",
    "    data = doc_df.to_dict('records')[0]\n",
    "    c = Counter()\n",
    "    c.update(w for w in (data['text'] + ' ' + data['auxiliary']).split() if len(w) > 1)\n",
    "    return data['url_name'] + ' ' + data['title_words'] + ' ' + \" \".join(w[0] for w in c.most_common(max_features))\n",
    "\n",
    "\n",
    "for i, mfeatures in enumerate(apply_to_subdf(filesdf, 'index', get_max_features, max_features=60), start=1):\n",
    "    filesdf.at[i, 'max_features'] = mfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:48:03.038797Z",
     "iopub.status.busy": "2021-05-31T12:48:03.038435Z",
     "iopub.status.idle": "2021-05-31T12:48:03.047308Z",
     "shell.execute_reply": "2021-05-31T12:48:03.046352Z",
     "shell.execute_reply.started": "2021-05-31T12:48:03.038752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc_id\n",
       "1    zrenielib аншина центр репродукция генетика фе...\n",
       "2    kak-perevesti-online перевод киви кошелёк коше...\n",
       "3    timecops проект патруль время реабилитация дух...\n",
       "4    proffi95 блог клуб преподавание начальный клас...\n",
       "Name: max_features, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesdf.max_features.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:48:03.049106Z",
     "iopub.status.busy": "2021-05-31T12:48:03.048743Z",
     "iopub.status.idle": "2021-05-31T12:48:03.059061Z",
     "shell.execute_reply": "2021-05-31T12:48:03.058281Z",
     "shell.execute_reply.started": "2021-05-31T12:48:03.049073Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(group_df, n_features):\n",
    "    datadf = filesdf.loc[group_df['doc_id'].values]\n",
    "\n",
    "    vec = TfidfVectorizer(sublinear_tf=True)\n",
    "    tfidf_matrix = vec.fit_transform(datadf.max_features)\n",
    "\n",
    "    distance_matrix = np.partition(pairwise_distances(tfidf_matrix, metric='cosine', n_jobs=-1), n_features, axis=1)[:, :n_features]\n",
    "    X = None\n",
    "    for func in [np.mean, np.average, np.median, np.std, np.var, np.max, np.min]:\n",
    "        res = func(distance_matrix, axis=0)\n",
    "        res_column = res[np.newaxis, :]\n",
    "        X = np.hstack((X if X is not None else distance_matrix, np.repeat(res_column, distance_matrix.shape[0], axis=0)))\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:48:03.060946Z",
     "iopub.status.busy": "2021-05-31T12:48:03.060383Z",
     "iopub.status.idle": "2021-05-31T12:48:03.069544Z",
     "shell.execute_reply": "2021-05-31T12:48:03.068682Z",
     "shell.execute_reply.started": "2021-05-31T12:48:03.060865Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features_for_dataframe(df):\n",
    "    X = None\n",
    "    for x in apply_to_subdf(df, 'group_id', extract_features, n_features=25):\n",
    "        X = sparse.vstack((X, x))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:48:03.071142Z",
     "iopub.status.busy": "2021-05-31T12:48:03.070723Z",
     "iopub.status.idle": "2021-05-31T12:48:03.080801Z",
     "shell.execute_reply": "2021-05-31T12:48:03.079963Z",
     "shell.execute_reply.started": "2021-05-31T12:48:03.071106Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = extract_features_for_dataframe(traindf)\n",
    "y_train = np.asarray(traindf['target'])\n",
    "groups = np.asarray(traindf['group_id'])\n",
    "\n",
    "scaler = StandardScaler(with_mean=False).fit(X_train, y_train)\n",
    "X_train = scaler.transform(X_train);\n",
    "\n",
    "searcher = GridSearchCV(SGDClassifier(), grid, scoring='f1', n_jobs=-1, pre_dispatch='2*n_jobs')\n",
    "searcher.fit(X_train, y_train, groups=groups);\n",
    "\n",
    "best_params = { 'n_jobs': -1 }\n",
    "best_params.update(searcher.best_params_)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверим наше предсказание на датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:48:03.082410Z",
     "iopub.status.busy": "2021-05-31T12:48:03.082045Z",
     "iopub.status.idle": "2021-05-31T12:48:03.090804Z",
     "shell.execute_reply": "2021-05-31T12:48:03.089979Z",
     "shell.execute_reply.started": "2021-05-31T12:48:03.082375Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_val, X_val, y_train_val, y_val = train_test_split(X_train, y_train, random_state=42)\n",
    "\n",
    "clf = SGDClassifier(**best_params).fit(X_train_val, y_train_val)\n",
    "y_pred = clf.predict(X_val)\n",
    "f1_score(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Считываем test и делаем predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:48:03.092621Z",
     "iopub.status.busy": "2021-05-31T12:48:03.092264Z",
     "iopub.status.idle": "2021-05-31T12:48:03.103653Z",
     "shell.execute_reply": "2021-05-31T12:48:03.102747Z",
     "shell.execute_reply.started": "2021-05-31T12:48:03.092587Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = extract_features_for_dataframe(testdf)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = SGDClassifier(**best_params).fit(X_train, y_train)\n",
    "testdf['target'] = clf.predict(X_test)\n",
    "\n",
    "testdf.drop(columns=['group_id', 'doc_id']).to_csv('solution2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итоговый скор 0.49922\n",
    "Хм, улучшения не почувствовалось, думаю потому, что признаки перестали зависеть линейно. Попробуем другой классификатор. Прежде чем это сделать добавим еще два признака: поможем кластеризацией и добавим длину текста как признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:48:03.105647Z",
     "iopub.status.busy": "2021-05-31T12:48:03.105262Z",
     "iopub.status.idle": "2021-05-31T12:48:03.272801Z",
     "shell.execute_reply": "2021-05-31T12:48:03.272028Z",
     "shell.execute_reply.started": "2021-05-31T12:48:03.105613Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:48:03.276122Z",
     "iopub.status.busy": "2021-05-31T12:48:03.275842Z",
     "iopub.status.idle": "2021-05-31T12:48:03.287232Z",
     "shell.execute_reply": "2021-05-31T12:48:03.286294Z",
     "shell.execute_reply.started": "2021-05-31T12:48:03.276096Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(group_df, tfidf, n_features):\n",
    "    datadf = filesdf.loc[group_df['doc_id'].values]\n",
    "    words = datadf.title_words.values\n",
    "    indices = group_df.index.values - 1\n",
    "    X = []\n",
    "    for i, current_words in enumerate(words):\n",
    "        distances = []\n",
    "        for j, another_words in enumerate(words):\n",
    "            if i == j:\n",
    "                continue\n",
    "            distances.append(len(set(current_words) & set(another_words)))\n",
    "        fueatures_to_add = (-np.partition(-np.asarray(distances, dtype='int'), 20)[:20])\n",
    "        X.append(-np.sort(-fueatures_to_add))\n",
    "        \n",
    "    X = np.asarray(X)\n",
    "    X = np.hstack((X, np.asarray([len(text) for text in datadf.text])[:, np.newaxis]))\n",
    "    \n",
    "    svd = TruncatedSVD(n_components=100)\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    lsa = make_pipeline(svd, normalizer)\n",
    "    norm_matrix = lsa.fit_transform(tfidf[indices])\n",
    "\n",
    "    km = KMeans(n_clusters=2, init='k-means++', max_iter=200)\n",
    "    km.fit(norm_matrix)\n",
    "    \n",
    "    X = np.hstack((X, km.labels_[:, np.newaxis]))\n",
    "\n",
    "    distance_matrix = np.sort(pairwise_distances(tfidf[indices], metric='cosine', n_jobs=-1), axis=1)[:, 1:n_features]\n",
    "    X = np.hstack((X, distance_matrix))\n",
    "    for func in [np.mean, np.average, np.median, np.std, np.max]:\n",
    "        res = func(distance_matrix, axis=0)\n",
    "        res_column = res[np.newaxis, :]\n",
    "        X = np.hstack((X, np.repeat(res_column, distance_matrix.shape[0], axis=0)))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:48:03.288832Z",
     "iopub.status.busy": "2021-05-31T12:48:03.288347Z",
     "iopub.status.idle": "2021-05-31T12:48:03.301186Z",
     "shell.execute_reply": "2021-05-31T12:48:03.300188Z",
     "shell.execute_reply.started": "2021-05-31T12:48:03.288797Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features_for_dataframe(df):\n",
    "    vec = TfidfVectorizer(sublinear_tf=True)\n",
    "    datadf = filesdf.loc[df['doc_id'].values]\n",
    "    tfidf_matrix = vec.fit_transform(datadf.max_features)\n",
    "\n",
    "    X = None\n",
    "    for x in apply_to_subdf(df, 'group_id', extract_features, tfidf=tfidf_matrix, n_features=25):\n",
    "        X = sparse.vstack((X, x))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:48:03.303001Z",
     "iopub.status.busy": "2021-05-31T12:48:03.302570Z",
     "iopub.status.idle": "2021-05-31T12:51:49.577824Z",
     "shell.execute_reply": "2021-05-31T12:51:49.576888Z",
     "shell.execute_reply.started": "2021-05-31T12:48:03.302967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3e83d89e46487c9094c8e78f9908ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((11690, 166), (11690,), (11690,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = extract_features_for_dataframe(traindf)\n",
    "y_train = np.asarray(traindf['target'])\n",
    "groups = np.asarray(traindf['group_id'])\n",
    "X_train.shape, y_train.shape, groups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:51:49.579728Z",
     "iopub.status.busy": "2021-05-31T12:51:49.579349Z",
     "iopub.status.idle": "2021-05-31T12:51:49.639297Z",
     "shell.execute_reply": "2021-05-31T12:51:49.638448Z",
     "shell.execute_reply.started": "2021-05-31T12:51:49.579684Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=False).fit(X_train, y_train)\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на скоры следующих классификаторов, прежде чем двигаться дальше. Будем целиться на xgboost stacking с топ 5 лучшими из получившихся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:51:49.641080Z",
     "iopub.status.busy": "2021-05-31T12:51:49.640712Z",
     "iopub.status.idle": "2021-05-31T12:51:49.761520Z",
     "shell.execute_reply": "2021-05-31T12:51:49.760735Z",
     "shell.execute_reply.started": "2021-05-31T12:51:49.641040Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:51:49.762977Z",
     "iopub.status.busy": "2021-05-31T12:51:49.762657Z",
     "iopub.status.idle": "2021-05-31T12:51:49.766085Z",
     "shell.execute_reply": "2021-05-31T12:51:49.765292Z",
     "shell.execute_reply.started": "2021-05-31T12:51:49.762950Z"
    }
   },
   "outputs": [],
   "source": [
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3, n_jobs=-1),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), n_jobs=-1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1, n_jobs=-1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:51:49.768101Z",
     "iopub.status.busy": "2021-05-31T12:51:49.767601Z",
     "iopub.status.idle": "2021-05-31T12:51:49.779501Z",
     "shell.execute_reply": "2021-05-31T12:51:49.778673Z",
     "shell.execute_reply.started": "2021-05-31T12:51:49.768067Z"
    }
   },
   "outputs": [],
   "source": [
    "def collect_scores(classifier):\n",
    "    clf.fit(X_train_val.A, y_train_val)\n",
    "    y_pred = clf.predict(X_val.A)\n",
    "    return f1_score(y_pred, y_val)\n",
    "\n",
    "scores = []\n",
    "for score in apply_to_array(classifiers, collect_scores):\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:51:49.782394Z",
     "iopub.status.busy": "2021-05-31T12:51:49.782164Z",
     "iopub.status.idle": "2021-05-31T12:51:49.790822Z",
     "shell.execute_reply": "2021-05-31T12:51:49.790016Z",
     "shell.execute_reply.started": "2021-05-31T12:51:49.782372Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.set(xlabel='Highest score')\n",
    "sns.barplot(x=names, y=scores, saturation=0.3, orient='v');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем сначала параметры для xgboosta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T12:51:49.792745Z",
     "iopub.status.busy": "2021-05-31T12:51:49.792203Z",
     "iopub.status.idle": "2021-05-31T12:51:49.869396Z",
     "shell.execute_reply": "2021-05-31T12:51:49.868631Z",
     "shell.execute_reply.started": "2021-05-31T12:51:49.792708Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T13:38:23.714507Z",
     "iopub.status.busy": "2021-05-31T13:38:23.714112Z",
     "iopub.status.idle": "2021-05-31T13:38:23.719173Z",
     "shell.execute_reply": "2021-05-31T13:38:23.718225Z",
     "shell.execute_reply.started": "2021-05-31T13:38:23.714477Z"
    }
   },
   "outputs": [],
   "source": [
    "def f1_eval(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    err = 1-f1_score(y_true, np.round(y_pred))\n",
    "    return 'f1_err', err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T13:38:23.869974Z",
     "iopub.status.busy": "2021-05-31T13:38:23.869638Z",
     "iopub.status.idle": "2021-05-31T13:38:23.873771Z",
     "shell.execute_reply": "2021-05-31T13:38:23.872975Z",
     "shell.execute_reply.started": "2021-05-31T13:38:23.869940Z"
    }
   },
   "outputs": [],
   "source": [
    "opt_params = {\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'predictor': 'gpu_predictor',\n",
    "    'verbosity': 0,\n",
    "    'eval_metrix': f1_eval\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T13:55:27.915216Z",
     "iopub.status.busy": "2021-05-31T13:55:27.914773Z",
     "iopub.status.idle": "2021-05-31T13:55:27.921831Z",
     "shell.execute_reply": "2021-05-31T13:55:27.920737Z",
     "shell.execute_reply.started": "2021-05-31T13:55:27.915170Z"
    }
   },
   "outputs": [],
   "source": [
    "def ValScore(X, y, groups, n_splits=5, *args, **kwargs):\n",
    "    kf = GroupKFold(n_splits=n_splits)\n",
    "    clf = (*args, **kwargs)\n",
    "\n",
    "    scores = []\n",
    "    for train, test in kf.split(X, y, groups=groups):\n",
    "        X_train, y_train = X.A[train], y[train]\n",
    "        X_test, y_test = X.A[test], y[test]\n",
    "        clf.fit(X_train, y_train)\n",
    "        scores.append(f1_score(y_pred=clf.predict(X_test),\n",
    "                               y_true=y_test))\n",
    "    return np.asarray(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T13:55:28.127403Z",
     "iopub.status.busy": "2021-05-31T13:55:28.127094Z",
     "iopub.status.idle": "2021-05-31T13:55:28.134063Z",
     "shell.execute_reply": "2021-05-31T13:55:28.133066Z",
     "shell.execute_reply.started": "2021-05-31T13:55:28.127376Z"
    }
   },
   "outputs": [],
   "source": [
    "def FindParams(X, y, groups, param_name, param_range, known_params=opt_params):\n",
    "    mean_scores = []\n",
    "\n",
    "    for param in param_range:\n",
    "        kwargs = known_params\n",
    "        kwargs.update({param_name: param})\n",
    "        scores = ValScore(X, y, groups, **kwargs)\n",
    "        mean_scores.append(scores.mean())\n",
    "\n",
    "    opt_param = param_range[np.argmax(mean_scores)]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel('score')\n",
    "    plt.title(f'Зависимость f1-score от параметра {param_name}\\n'\n",
    "              f'Оптимальное значение параметра {param_name}: {opt_param}')\n",
    "    plt.plot(param_range, mean_scores)\n",
    "\n",
    "    return opt_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T13:55:28.328430Z",
     "iopub.status.busy": "2021-05-31T13:55:28.328111Z",
     "iopub.status.idle": "2021-05-31T13:55:28.334834Z",
     "shell.execute_reply": "2021-05-31T13:55:28.333817Z",
     "shell.execute_reply.started": "2021-05-31T13:55:28.328403Z"
    }
   },
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'objective': ['binary:logistic', 'binary:hinge'],\n",
    "    'n_estimators': np.linspace(20, 200, 30).astype(int),\n",
    "    'booster': ['gbtree'],\n",
    "    'eta': np.arange(0.05, 0.3, 0.05),\n",
    "    'gamma': np.logspace(2, -3, 5),\n",
    "    'max_depth': np.arange(3, 10, 2).astype(int),\n",
    "    'min_child_weigth': np.logspace(0, -4, 5),\n",
    "    'subsampe': np.arange(0.4, 1, 0.1),\n",
    "    'alpha': np.logspace(1, -4, 5),\n",
    "    'colsample_bytree': np.arange(0.5, 1, 0.1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T13:55:28.604971Z",
     "iopub.status.busy": "2021-05-31T13:55:28.604618Z",
     "iopub.status.idle": "2021-05-31T13:55:28.694073Z",
     "shell.execute_reply": "2021-05-31T13:55:28.691953Z",
     "shell.execute_reply.started": "2021-05-31T13:55:28.604942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-78068a497473>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrange_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mopt_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFindParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mopt_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt_param\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-170-a1463e2b4070>\u001b[0m in \u001b[0;36mFindParams\u001b[0;34m(X, y, groups, param_name, param_range, known_params)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknown_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mValScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mmean_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-169-e7f091002682>\u001b[0m in \u001b[0;36mValScore\u001b[0;34m(X, y, groups, n_splits, *args, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         scores.append(f1_score(y_pred=clf.predict(X_test),\n\u001b[1;32m     11\u001b[0m                                y_true=y_test))\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m             \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m         )\n\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    195\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "for param_name in grid:\n",
    "    range_ = grid[param_name]\n",
    "    opt_param = FindParams(X_train_scaled, y_train, groups, param_name, range_, opt_params)\n",
    "    opt_params.update({param_name: opt_param})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из-за этой ошибки я так и не смог получил скор, который возможно мог бы поднять меня вышел в лидерборде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-31T12:51:58.761408Z",
     "iopub.status.idle": "2021-05-31T12:51:58.761791Z"
    }
   },
   "outputs": [],
   "source": [
    "opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-31T12:51:58.762820Z",
     "iopub.status.idle": "2021-05-31T12:51:58.763294Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_val, X_val, y_train_val, y_val = train_test_split(X_train, y_train, random_state=42)\n",
    "\n",
    "clf = xgb.XGBClassifier(**opt_params).fit(X_train_val, y_train_val)\n",
    "y_pred = clf.predict(X_val)\n",
    "f1_score(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-31T12:51:58.765992Z",
     "iopub.status.idle": "2021-05-31T12:51:58.766560Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = extract_features_for_dataframe(testdf)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = xgb.XGBClassifier(**best_params).fit(X_train, y_train)\n",
    "testdf['target'] = clf.predict(X_test)\n",
    "\n",
    "testdf.drop(columns=['group_id', 'doc_id']).to_csv('solution3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше жалкие попытки попробовать другие алгоритмы("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = {\n",
    "    'n_jobs': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'criterion': ['gini'],\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [6],\n",
    "    'min_samples_split': [1, 2, 3],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = GridSearchCV(RandomForestClassifier(**opt_params), grid, n_jobs=-1,  scoring='f1', pre_dispatch='2*n_jobs', verbose=1)\n",
    "searcher.fit(X_train, y_train, groups=groups);\n",
    "opt_params.update(searcher.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_val, y_train_val, y_val = train_test_split(X_train, y_train, random_state=42)\n",
    "\n",
    "clf = xgb.RandomForestClassifier(**opt_params).fit(X_train_val, y_train_val)\n",
    "y_pred = clf.predict(X_val)\n",
    "f1_score(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = extract_features_for_dataframe(testdf)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(**opt_params).fit(X_train_scaled, y_train)\n",
    "testdf['target'] = clf.predict(X_test_scaled)\n",
    "\n",
    "testdf.drop(columns=['group_id', 'doc_id']).to_csv('solution3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.59047"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = {\n",
    "    'max_depth': 6,\n",
    "    'reg_alpha': 0.01,\n",
    "    'objective': 'binary',\n",
    "    'max_bin': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier(**opt_params).fit(X_tr_scaled, y_train)\n",
    "testdf['target'] = clf.predict(X_test_scaled)\n",
    "\n",
    "testdf.drop(columns=['group_id', 'doc_id']).to_csv('solution4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.61313"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что-то пошло не так, и я к сожалению не совсем понял где. Есть подозрение, что признаки по косинусовым расстояниям выбирались неправильно. Я брал слова часто встречаемые во всех документах, при этом совсем не обращал внимания на слова в документах, помеченных 1. Это должно быть важно, так как есть группы в которых правильных документов намного меньше, чем неправильных, что и сыграло злую шутку. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также думаю, что подход был изначально неправильный, стоило сначала попробовать все алгоритмы на первых данных, затем только добавлять новые фичи и смотреть улучшился ли скор или нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве признаков можно было бы еще брать количество картинок в документе, доступен ли документ на данный момент и есть ли у данного документа редирект на какой-нибудь сайт. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Топ2 в соревновании заняли алгоритмы CatBoost и XGBoost, некоторые использовали DBSCAN для определения выбросов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
