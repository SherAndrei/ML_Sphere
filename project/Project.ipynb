{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003945f8",
   "metadata": {},
   "source": [
    "## Проект \"Анализ веб-документов\" Техносфера Весна 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8ad46b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb98a2cd",
   "metadata": {},
   "source": [
    "### Посмотрим на наши трейновые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "944c8641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11690, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>15764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>14852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         group_id  doc_id  target\n",
       "pair_id                          \n",
       "1               1   15731       0\n",
       "2               1   14829       0\n",
       "3               1   15764       0\n",
       "4               1   17669       0\n",
       "5               1   14852       0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf = pd.read_csv('data/train_groups.csv', sep=',', index_col='pair_id')\n",
    "print(traindf.shape)\n",
    "traindf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd8f5e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45050500",
   "metadata": {},
   "source": [
    "# Идея 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db923286",
   "metadata": {},
   "source": [
    "Посмотрим на каждые заголовки, построим множество признаков, основанных на количестве схожих слов в заголовках.\n",
    "Будем брать топ 15 в списке"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3979cffc",
   "metadata": {},
   "source": [
    "## Решение 0\n",
    "Повторим решение со второй домашней работы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93d572e",
   "metadata": {},
   "source": [
    "1. Прочитаем все заголовки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3dd890ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15731</th>\n",
       "      <td>ВАЗ 21213 | Замена подшипников ступицы | Нива</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14829</th>\n",
       "      <td>Ваз 2107 оптом в Сочи. Сравнить цены, купить п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15764</th>\n",
       "      <td>Купить ступица Лада калина2. Трансмиссия - пер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17669</th>\n",
       "      <td>Классика 21010 - 21074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title\n",
       "15731      ВАЗ 21213 | Замена подшипников ступицы | Нива\n",
       "14829  Ваз 2107 оптом в Сочи. Сравнить цены, купить п...\n",
       "15764  Купить ступица Лада калина2. Трансмиссия - пер...\n",
       "17669                             Классика 21010 - 21074"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_to_title = {}\n",
    "\n",
    "with open('data/docs_titles.tsv') as f:\n",
    "    for num_line, line in enumerate(f):\n",
    "        if num_line == 0:\n",
    "            continue\n",
    "        data = line.strip().split('\\t', 1)\n",
    "        doc_to_title[int(data[0])] = '' if len(data) == 1 else data[1]\n",
    "\n",
    "filesdf = pd.DataFrame.from_dict(doc_to_title, orient='index', columns=['title'])\n",
    "filesdf.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbe1822",
   "metadata": {},
   "source": [
    "2. Прочитаем трейн и добавим заголовки к нему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "26ac1895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>target</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15731</td>\n",
       "      <td>0</td>\n",
       "      <td>ВАЗ 21213 | Замена подшипников ступицы | Нива</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14829</td>\n",
       "      <td>0</td>\n",
       "      <td>Ваз 2107 оптом в Сочи. Сравнить цены, купить п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>15764</td>\n",
       "      <td>0</td>\n",
       "      <td>Купить ступица Лада калина2. Трансмиссия - пер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17669</td>\n",
       "      <td>0</td>\n",
       "      <td>Классика 21010 - 21074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         group_id  doc_id  target  \\\n",
       "pair_id                             \n",
       "1               1   15731       0   \n",
       "2               1   14829       0   \n",
       "3               1   15764       0   \n",
       "4               1   17669       0   \n",
       "\n",
       "                                                     title  \n",
       "pair_id                                                     \n",
       "1            ВАЗ 21213 | Замена подшипников ступицы | Нива  \n",
       "2        Ваз 2107 оптом в Сочи. Сравнить цены, купить п...  \n",
       "3        Купить ступица Лада калина2. Трансмиссия - пер...  \n",
       "4                                   Классика 21010 - 21074  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_titles(df):\n",
    "    df['title'] = filesdf.loc[df['doc_id'].values].values\n",
    "\n",
    "traindf = pd.read_csv('data/train_groups.csv', index_col='pair_id')\n",
    "add_titles(traindf)\n",
    "traindf.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252de18e",
   "metadata": {},
   "source": [
    "3. Найдем признаки. Посчитаем общие слова для всех групп и всех веб-страниц в заголовке. Как признаки для веб-страницы, возьмем значения топ-15  пересечений с другими страницами из группы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2e90886",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, groups = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ed8f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_titles_for_train(docs):\n",
    "    titles = docs.title\n",
    "    y_train.extend(docs.target.to_list())\n",
    "    groups.extend(docs.group_id.to_list())\n",
    "    for i, title in enumerate(titles):\n",
    "        words = set(title.strip().split())\n",
    "        distances = []\n",
    "        for j, another_title in enumerate(titles):\n",
    "            if i == j:\n",
    "                continue\n",
    "            another_words = set(another_title.strip().split())\n",
    "            distances.append(len(words.intersection(another_words)))\n",
    "        fueatures_to_add = (-np.partition(-np.asarray(distances, dtype='int'), 15)[:15])\n",
    "        X_train.append(-np.sort(-fueatures_to_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6a181508",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.groupby('group_id').apply(collect_titles_for_train);\n",
    "X, y, groups = np.asarray(X_train), np.asarray(y_train), np.asarray(groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca04a5",
   "metadata": {},
   "source": [
    "4. Отмасштабируем входные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "314ff332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9e6c773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X, y)\n",
    "X = scaler.transform(X);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f76be",
   "metadata": {},
   "source": [
    "5. Подберем гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d6d8f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e781774",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = {\n",
    "    'n_jobs': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "182f34fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ValScore(clf, X_val, y_val, groups, n_splits=5, *args, **kwargs):\n",
    "    clf = clf(*args, **kwargs)\n",
    "    kf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    scores = []\n",
    "    for train, test in kf.split(X_val, y_val, groups=groups):\n",
    "        clf.fit(X_val[train], y_val[train])\n",
    "        scores.append(f1_score(y_pred=clf.predict(X_val[test]),\n",
    "                               y_true=y_val[test]))\n",
    "    return np.asarray(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fb0a4007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindParams(clf, X_val, y_val, groups, param_name, param_range, known_params=opt_params):\n",
    "    mean_scores = []\n",
    "\n",
    "    for param in param_range:\n",
    "        kwargs = known_params\n",
    "        kwargs.update({param_name: param})\n",
    "        \n",
    "        scores = ValScore(clf, X_val, y_val, groups, **kwargs)\n",
    "        mean_scores.append(scores.mean())\n",
    "\n",
    "    opt_param = param_range[np.argmax(mean_scores)]\n",
    "    return opt_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5e18bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'max_iter': [500, 1000, 2000, 3000, 5000],\n",
    "    'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "    'alpha': np.logspace(4, -4, 10)\n",
    "}\n",
    "\n",
    "for param in grid:\n",
    "    param_range = grid[param]\n",
    "    opt_model_type = FindParams(SGDClassifier, X, y, groups, param, param_range, opt_params)\n",
    "    opt_params.update({param: opt_model_type})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "569e76e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_jobs': -1, 'max_iter': 3000, 'loss': 'hinge', 'alpha': 0.0001}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a6b330",
   "metadata": {},
   "source": [
    "### Считываем test и делаем predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee3104fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11691</th>\n",
       "      <td>130</td>\n",
       "      <td>6710</td>\n",
       "      <td>КАК ПРОПИСАТЬ АДМИНКУ В КС 1.6 СЕБЕ ИЛИ ДРУГУ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11692</th>\n",
       "      <td>130</td>\n",
       "      <td>4030</td>\n",
       "      <td>Скачать: SGL-RP доработка | Слив мода [MySQL] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11693</th>\n",
       "      <td>130</td>\n",
       "      <td>5561</td>\n",
       "      <td>Как прописать админку в кс 1.6 - Counter-Strik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11694</th>\n",
       "      <td>130</td>\n",
       "      <td>4055</td>\n",
       "      <td>Как прописать простую админку в кс 1 6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         group_id  doc_id                                              title\n",
       "pair_id                                                                     \n",
       "11691         130    6710  КАК ПРОПИСАТЬ АДМИНКУ В КС 1.6 СЕБЕ ИЛИ ДРУГУ ...\n",
       "11692         130    4030  Скачать: SGL-RP доработка | Слив мода [MySQL] ...\n",
       "11693         130    5561  Как прописать админку в кс 1.6 - Counter-Strik...\n",
       "11694         130    4055             Как прописать простую админку в кс 1 6"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf = pd.read_csv('data/test_groups.csv', index_col='pair_id')\n",
    "add_titles(testdf)\n",
    "testdf.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "544dba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ef330231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_titles_for_test(docs):\n",
    "    titles = docs.title\n",
    "    for i, title in enumerate(titles):\n",
    "        words = set(title.strip().split())\n",
    "        distances = []\n",
    "        for j, another_title in enumerate(titles):\n",
    "            if i == j:\n",
    "                continue\n",
    "            another_words = set(another_title.strip().split())\n",
    "            distances.append(len(words.intersection(another_words)))\n",
    "        fueatures_to_add = (-np.partition(-np.asarray(distances, dtype='int'), 15)[:15])\n",
    "        X_test.append(-np.sort(-fueatures_to_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9653c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.groupby('group_id').apply(collect_titles_for_test);\n",
    "X_test = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8fd63870",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "770aa6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(**opt_params).fit(X, y)\n",
    "testdf['target'] = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2d80591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.drop(columns=['group_id', 'doc_id', 'title']).to_csv('solution0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2976ced",
   "metadata": {},
   "source": [
    "### Итоговый скор 0.51976\n",
    "Надо что-то получше"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e841b4",
   "metadata": {},
   "source": [
    "# Идея 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925d9d9a",
   "metadata": {},
   "source": [
    "Посмотрим на слова в получившихся данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "375e0e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b7cce149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('-', 11915), ('в', 6517), ('и', 5654), ('|', 4754), ('на', 4269)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCounter = Counter()\n",
    "for title in filesdf['title'].values:\n",
    "    wordCounter.update(title.strip().split())\n",
    "wordCounter.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7384028c",
   "metadata": {},
   "source": [
    "Явно среди заголовков оказалось куча мусора и бесполезной информации.\n",
    "Давайте предобработаем заголовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5c8061c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import corpus, word_tokenize\n",
    "from string import digits, punctuation\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ee4ddaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "chars_to_remove = digits + punctuation + \"–—«»№•❤★✿╬·\"\n",
    "morph = MorphAnalyzer()\n",
    "RU_stopwords = set(corpus.stopwords.words('russian'))\n",
    "EN_stopwords = set(corpus.stopwords.words('english'))\n",
    "GE_stopwords = set(corpus.stopwords.words('german'))\n",
    "stopwords = RU_stopwords.union(EN_stopwords.union(GE_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7080852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    if text is None:\n",
    "        return\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    text = text.translate(str.maketrans('', '', chars_to_remove))\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word not in stopwords and len(word) > 1]\n",
    "    words = [morph.parse(word)[0].normal_form for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ab21c2f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-862147bc373f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilesdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title_words'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilesdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/da/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4136\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4138\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-6d39a527fa1c>\u001b[0m in \u001b[0;36mprocess_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_form\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-6d39a527fa1c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_form\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/da/lib/python3.7/site-packages/pymorphy2/analyzer.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_to_parses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/da/lib/python3.7/site-packages/pymorphy2/analyzer.py\u001b[0m in \u001b[0;36mapply_to_parses\u001b[0;34m(self, word, word_lower, parses)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         probs = [self.p_t_given_w.prob(word_lower, tag)\n\u001b[0;32m---> 78\u001b[0;31m                 for (word, tag, normal_form, score, methods_stack) in parses]\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/da/lib/python3.7/site-packages/pymorphy2/analyzer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         probs = [self.p_t_given_w.prob(word_lower, tag)\n\u001b[0;32m---> 78\u001b[0;31m                 for (word, tag, normal_form, score, methods_stack) in parses]\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/da/lib/python3.7/site-packages/pymorphy2/dawg.py\u001b[0m in \u001b[0;36mprob\u001b[0;34m(self, word, tag)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mdawg_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s:%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdawg_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMULTIPLIER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/da/lib/python3.7/site-packages/dawg_python/dawgs.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLOOKUP_ERROR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/da/lib/python3.7/site-packages/dawg_python/dawgs.py\u001b[0m in \u001b[0;36mb_get_value\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mb_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/da/lib/python3.7/site-packages/dawg_python/wrapper.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;34m\"Exact matching (returns value)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfollow_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROOT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/da/lib/python3.7/site-packages/dawg_python/wrapper.py\u001b[0m in \u001b[0;36mfollow_bytes\u001b[0;34m(self, s, index)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;34m\"Follows transitions.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfollow_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_from_byte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/da/lib/python3.7/site-packages/dawg_python/wrapper.py\u001b[0m in \u001b[0;36mfollow_char\u001b[0;34m(self, label, index)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfollow_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;34m\"Follows a transition\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_units\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mnext_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m^\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m^\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRECISION_MASK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/da/lib/python3.7/site-packages/dawg_python/units.py\u001b[0m in \u001b[0;36moffset\u001b[0;34m(base)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;34m\"\"\" Read an offset to child units from a non-leaf unit. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mEXTENSION_BIT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mPRECISION_MASK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filesdf['title_words'] = filesdf['title'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdca838",
   "metadata": {},
   "outputs": [],
   "source": [
    "filesdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bb5e3c",
   "metadata": {},
   "source": [
    "Проверим как изменились наши заголовки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0188f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wordCounter = Counter()\n",
    "for words in filesdf['title_words'].values:\n",
    "    new_wordCounter.update(words)\n",
    "new_wordCounter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fc1046",
   "metadata": {},
   "source": [
    "Уже лучше, попробуем запустить решение 0 на этих данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58de8cf",
   "metadata": {},
   "source": [
    "## Решение 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae49799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_title_words(df):\n",
    "    df['title_words'] = [words for words in filesdf.loc[df['doc_id'].values]['title_words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0160ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_title_words(traindf)\n",
    "traindf.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3153e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, groups = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e53840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_words_impl__(train_matrix, words):\n",
    "    for i, current_words in enumerate(words):\n",
    "        distances = []\n",
    "        for j, another_words in enumerate(words):\n",
    "            if i == j:\n",
    "                continue\n",
    "            distances.append(len(set(current_words) & set(another_words)))\n",
    "        fueatures_to_add = (-np.partition(-np.asarray(distances, dtype='int'), 15)[:15])\n",
    "        train_matrix.append(-np.sort(-fueatures_to_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97061d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_title_words_for_train(docs):\n",
    "    y_train.extend(docs.target.to_list())\n",
    "    groups.extend(docs.group_id.to_list())\n",
    "    collect_words_impl__(X_train, docs.title_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0538510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.groupby('group_id').apply(collect_title_words_for_train);\n",
    "X, y, groups = np.asarray(X_train), np.asarray(y_train), np.asarray(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99676ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X, y)\n",
    "X = scaler.transform(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = {\n",
    "    'n_jobs': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd445b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in grid:\n",
    "    param_range = grid[param]\n",
    "    opt_model_type = FindParams(SGDClassifier, X, y, groups, param, param_range, opt_params)\n",
    "    opt_params.update({param: opt_model_type})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2cde01",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e64d10",
   "metadata": {},
   "source": [
    "### Считываем test и делаем predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc4e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7f62e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_title_words_for_test(docs):\n",
    "    collect_words_impl__(X_test, docs.title_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f96906",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv('data/test_groups.csv', index_col='pair_id')\n",
    "add_title_words(testdf)\n",
    "testdf.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd5940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.groupby('group_id').apply(collect_title_words_for_test);\n",
    "X_test = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d8cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea293856",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(**opt_params).fit(X, y)\n",
    "testdf['target'] = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539094ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.drop(columns=['group_id', 'doc_id', 'title_words']).to_csv('solution1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf50839",
   "metadata": {},
   "source": [
    "### Итоговый скор 0.63423\n",
    "Ура, побили бейзлайн!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb1d5bb",
   "metadata": {},
   "source": [
    "# Идея 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca4e907",
   "metadata": {},
   "source": [
    "Явно самих заголовков не хватает. Давайте обкачаем наши данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d4aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2710ccb0",
   "metadata": {},
   "source": [
    "Уберем ненужную колонку с заголовком"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757786cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.drop(columns=['title'], inplace=True)\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53705eed",
   "metadata": {},
   "source": [
    "Добавим имя URL без домена и путь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef89e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_url(url):\n",
    "    first_slash = url.find('/')\n",
    "    if first_slash != -1:\n",
    "        last_dot = url[:first_slash].rfind('.')\n",
    "        rest_url = url[first_slash + 1:]\n",
    "    else:\n",
    "        last_dot = url.rfind('.')\n",
    "        rest_url = \"\"\n",
    "    name = url[:last_dot]\n",
    "    return {\n",
    "        \"url_name\": name,\n",
    "        \"url_path\": process_text(rest_url)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ee6c9d",
   "metadata": {},
   "source": [
    "Из головы достанем верификацию от гугла, а также информацию о ключевых словах и описании"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c08caba",
   "metadata": {},
   "source": [
    "Интуиция подсказывает, что в keywords и desription будут лежать примерно одни и те же слова. Вместо двух листов использовать один словарь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d8d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_head(head):\n",
    "    verified = int(head.find('meta', attrs={'name': \"google-site-verification\"}) is not None)\n",
    "\n",
    "    keywords = head.find('meta', attrs={'name': \"keywords\"})\n",
    "    keywords = [] if keywords is None else process_text(keywords['content'])\n",
    "\n",
    "    description = head.find('meta', attrs={'name': \"description\"})\n",
    "    description = [] if description is None else process_text(description['content'])\n",
    "    \n",
    "    return {\n",
    "        'verified': verified,\n",
    "        'auxiliary': set(keywords).union(description)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990e5717",
   "metadata": {},
   "source": [
    "Из тела возьмем весь читабельный текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a1f478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_visible_text(body):\n",
    "    texts = body.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)\n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "def process_body(body):\n",
    "    return {\n",
    "        \"text\": process_text(get_visible_text(body))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52dc500",
   "metadata": {},
   "source": [
    "Функция обработки страницы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f6aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_page(file):\n",
    "    soup = BeautifulSoup(file, 'html.parser')\n",
    "    page_info = dict()\n",
    "    page_info.update(process_head(soup.find('head')))\n",
    "    page_info.update(process_body(soup.find('body')))\n",
    "    return page_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5711cc96",
   "metadata": {},
   "source": [
    "Посмотрим на какой-нибудь файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d4c7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('content/1.dat', 'r', 'utf-8') as f:\n",
    "     print(process_page(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1342f3c7",
   "metadata": {},
   "source": [
    "Слов получилось много, держать для каждого файла эти слова в памяти будет очень затратно. Будем сразу создавать признаки для наших файлов и держать их в таблице."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f3cc93",
   "metadata": {},
   "source": [
    "# Идея 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1c0031",
   "metadata": {},
   "source": [
    "Также очевидно, что использовать метрику наибольшего количества похожих слов из первых двух решений будет странновато. Есть такие слова как \"как\", \"ваш\" и др., которые встречаются в документах чаще остальных и не являются стоп-словами. Идея состоим в том, чтобы в качестве признаков использовать CountVectorizer на title_words, auiiliary, так как чаще всего эти данные поменьше и логичнее смотреть на количество в их схожести, и TfIdfVectorizer для всего остального текста на сайте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8d5fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c692ebd4",
   "metadata": {},
   "source": [
    "Попробуем получить признаки для первой группы из трейна:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159d2192",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupdf = traindf[traindf.group_id == 1].set_index(\"doc_id\").drop(columns=[\"group_id\"])\n",
    "groupdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cdeddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_id in tqdm(groupdf.index):\n",
    "    with codecs.open(f'content/{doc_id}.dat', 'r', 'utf-8') as f:\n",
    "        data = process_page(f)\n",
    "        groupdf.loc[doc_id, data.keys()] = data.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d034e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupdf.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff06c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcopy = groupdf.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004a05b3",
   "metadata": {},
   "source": [
    "Для больших матриц векторайзеры возвращают sparce матрицы, объединим их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab4a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5993cfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect = CountVectorizer(analyzer=lambda x: x, max_features=20)\n",
    "tfidfvect = TfidfVectorizer(analyzer=lambda x: x, max_features=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b241eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_matr = cvect.fit_transform(gcopy.pop('title_words').values)\n",
    "aux_matr   = cvect.fit_transform(gcopy.pop('auxiliary').values)\n",
    "text_matr  = tfidfvect.fit_transform(gcopy.pop('text').values)\n",
    "ver_col = gcopy.pop('verified').values[:, np.newaxis].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350af47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sparse.hstack((ver_col, title_matr, aux_matr, text_matr))\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917c432f",
   "metadata": {},
   "source": [
    "Проверим на этой группе хорошо ли получится предсказывать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c6a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbffdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train, groupdf['target'].values\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y, random_state=10)\n",
    "groups = np.ones(X_train.shape[0]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e80537",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=False).fit(X_train, y_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f4c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = {\n",
    "    'n_jobs': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d94a489",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'metric': ['euclidean', 'cosine'],\n",
    "    'k_neighbours': np.arange(1, 30)\n",
    "}\n",
    "\n",
    "for param in grid:\n",
    "    param_range = grid[param]\n",
    "    opt_model_type = FindParams(param, param_range, KNeighborsClassifier, opt_params)\n",
    "    opt_params.update({param: opt_model_type})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6cdb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(metric='cosine').fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "f1_score(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff6a9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8cd67a9",
   "metadata": {},
   "source": [
    "Обкачивать будем многопоточно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3276df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pool, Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fdb9df",
   "metadata": {},
   "source": [
    "Держать в памяти обкаченные данные каждого документа довольно бредово, так как не хватит памяти. Давайте сразу будем заполнять признаки для трейна. Заполним очередь трейновыми группами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e29d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = Queue()\n",
    "for group_id in traindf.group_id.unique():\n",
    "    queue.put(group_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be141b",
   "metadata": {},
   "source": [
    "Мы знаем, что в двух разных группах может быть один и тот же документ. Это может нам выстрелить в ногу в при работе с многопоточными программами. Выход: можно открывать файл под локом, сохранять его данные в суп, выходить из лока и обрабатывать признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d61247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_page_wrapper(i):\n",
    "#     while not queue.empty():\n",
    "#         group_id = queue.get()\n",
    "\n",
    "#         groupdf = traindf[traindf.group_id == group_id]\n",
    "#         with lock:\n",
    "#             with codecsecs.open(f'content/{doc_id}.dat', 'r', 'utf-8') as f:\n",
    "#                 current_data = process_page(f)\n",
    "\n",
    "#             with lock:\n",
    "#                 filesdf.loc[doc_id, current_data.keys()] = current_data.values()\n",
    "#                 pbar.update(1)\n",
    "\n",
    "\n",
    "# with Pool(processes=6) as pool, tqdm(total=queue.qsize()) as pbar:\n",
    "#     lock = pbar.get_lock()\n",
    "#     pool.map(get_features_wrapper, range(pool._processes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca9db7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a8d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filesdf.loc[1, current_data.keys()] = current_data.values()a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf890f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filesdf.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f22f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "Идея состоит в том, чтобы собрать"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b1e1c7",
   "metadata": {},
   "source": [
    "## Решение 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b83a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(f'content/1.dat', 'r', 'utf-8') as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfbe48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['doc_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ea2fba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('da': conda)",
   "language": "python",
   "name": "python3710jvsc74a57bd0fb1e9936674d641b0e1ac5c75cd75c2e7215014ff333cadbd6ad2f998d1f79a6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
